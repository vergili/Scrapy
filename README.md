Scrapy
======



##### Sitemap Spider



##### URL Rules


##### Clean URL

##### Get Stat 


##### Scrapy BaseSpider Class

https://github.com/wallunit/cocktail-search/blob/master/crawler/cocktails/spiders/monkey47.py
https://github.com/wallunit/cocktail-search/blob/master/crawler/cocktails/spiders/dradamsbitters.py


##### ScrapyCrawlSpider Class
https://github.com/wallunit/cocktail-search/blob/master/crawler/cocktails/spiders/cocktailtimes.py


#####  Base and Crawl Spider  
http://stackoverflow.com/questions/21556644/basespider-and-crawlspider-together

##### Scrapy Couch Data Base

http://stackoverflow.com/questions/22467111/scrapy-couchebase-middleware-or-pipline-how-to-store-and-retrieve-data

##### Duplicated filter  (in file)
http://stackoverflow.com/questions/12553117/how-to-filter-duplicate-requests-based-on-url-in-scrapy

##### Scrapyd   setting 
    $ curl http://localhost:6800/schedule.json -d project=myproject -d spider=somespider -d setting=DOWNLOAD_DELAY=2 -d arg1=val1

























